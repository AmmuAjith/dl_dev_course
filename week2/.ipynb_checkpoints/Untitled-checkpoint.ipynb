{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (250000, 28, 28, 1))\n",
      "('y_train shape:', (250000,))\n",
      "(250000, 'train samples')\n",
      "(250000, 'test samples')\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Input_layer (InputLayer)         (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Conv01_layerA (Conv2D)           (None, 28, 28, 32)    320         Input_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "Conv01_layerB (Conv2D)           (None, 28, 28, 32)    320         Input_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "Conv02_layerA (Conv2D)           (None, 26, 26, 32)    9248        Conv01_layerA[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Conv02_layerB (Conv2D)           (None, 26, 26, 32)    9248        Conv01_layerB[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "MaxPool01_layerA (MaxPooling2D)  (None, 13, 13, 32)    0           Conv02_layerA[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "AvgPool01_layerB (AveragePooling (None, 13, 13, 32)    0           Conv02_layerB[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Dropout01_layerA (Dropout)       (None, 13, 13, 32)    0           MaxPool01_layerA[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "Dropout01_layerB (Dropout)       (None, 13, 13, 32)    0           AvgPool01_layerB[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 13, 13, 64)    0           Dropout01_layerA[0][0]           \n",
      "                                                                   Dropout01_layerB[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "Conv03_layerA (Conv2D)           (None, 13, 13, 64)    36928       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Conv03_layerB (Conv2D)           (None, 13, 13, 64)    36928       concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Conv04_layerA (Conv2D)           (None, 11, 11, 64)    36928       Conv03_layerA[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Conv04_layerB (Conv2D)           (None, 11, 11, 64)    36928       Conv03_layerB[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "MaxPool02_layerA (MaxPooling2D)  (None, 5, 5, 64)      0           Conv04_layerA[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "AvgPool02_layerB (AveragePooling (None, 5, 5, 64)      0           Conv04_layerB[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Dropout02_layerA (Dropout)       (None, 5, 5, 64)      0           MaxPool02_layerA[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "Dropout02_layerB (Dropout)       (None, 5, 5, 64)      0           AvgPool02_layerB[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 5, 5, 128)     0           Dropout02_layerA[0][0]           \n",
      "                                                                   Dropout02_layerB[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "Flatten_layer (Flatten)          (None, 3200)          0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Dense_layer (Dense)              (None, 512)           1638912     Flatten_layer[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "Dropout03_layer (Dropout)        (None, 512)           0           Dense_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "logits_layer (Dense)             (None, 100)           51300       Dropout03_layer[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "Sofftmax_layer (Activation)      (None, 100)           0           logits_layer[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 1,857,060\n",
      "Trainable params: 1,857,060\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/preprocessing/image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (250000, 28, 28, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "#from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D ,AveragePooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.load('x_data_100_classes_5k.npy.zip')['x_data_100_classes_5k']\n",
    "data = np.array(map(lambda x : np.reshape(x,(28,28,1)) , data))\n",
    "\n",
    "#plt.imshow(data[9999]);plt.show()\n",
    "#plt.imshow(data[10000]);plt.show()\n",
    "y = np.zeros(500000 ,dtype = np.uint8)\n",
    "label = 0\n",
    "counter = 0\n",
    "for i in range(len(data)):\n",
    "    y[i] = label\n",
    "    counter += 1\n",
    "    if counter==5000:\n",
    "        counter = 0\n",
    "        label += 1\n",
    "    \n",
    "batch_size = 320\n",
    "num_classes = 100\n",
    "epochs = 20\n",
    "\n",
    "x_train ,y_train = data[0::2],y[0::2]\n",
    "x_test, y_test = data[1::2],y[1::2]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "Inp = Input(shape=(28,28,1),name = 'Input_layer')\n",
    "#ConvBlock 01\n",
    "conv01a = Conv2D(32, (3, 3), padding='same',activation = 'relu', input_shape=Inp.shape,name = 'Conv01_layerA')(Inp)\n",
    "conv02a = Conv2D(32, (3, 3),activation = 'relu',name = 'Conv02_layerA')(conv01a)\n",
    "maxpool_01a = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool01_layerA')(conv02a)\n",
    "drop01a = Dropout(0.25,name = 'Dropout01_layerA')(maxpool_01a)\n",
    "\n",
    "conv01b = Conv2D(32, (3, 3), padding='same',activation = 'relu', input_shape=Inp.shape,name = 'Conv01_layerB')(Inp)\n",
    "conv02b = Conv2D(32, (3, 3),activation = 'relu',name = 'Conv02_layerB')(conv01b)\n",
    "avgpool_01b = AveragePooling2D(pool_size=(2, 2),name = 'AvgPool01_layerB')(conv02b)\n",
    "drop01b = Dropout(0.25,name = 'Dropout01_layerB')(avgpool_01b)\n",
    "\n",
    "drop01 = keras.layers.concatenate([drop01a,drop01b])\n",
    "#Convblock 02\n",
    "conv03a = Conv2D(64, (3, 3), padding='same',activation = 'relu',name = 'Conv03_layerA')(drop01)\n",
    "conv04a = Conv2D(64, (3, 3),activation = 'relu',name = 'Conv04_layerA')(conv03a)\n",
    "maxpool_02a = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool02_layerA')(conv04a)\n",
    "drop02a = Dropout(0.25,name = 'Dropout02_layerA')(maxpool_02a)\n",
    "\n",
    "conv03b = Conv2D(64, (3, 3), padding='same',activation = 'relu',name = 'Conv03_layerB')(drop01)\n",
    "conv04b = Conv2D(64, (3, 3),activation = 'relu',name = 'Conv04_layerB')(conv03b)\n",
    "Avgpool_02b = AveragePooling2D(pool_size=(2, 2),name = 'AvgPool02_layerB')(conv04b)\n",
    "drop02b = Dropout(0.25,name = 'Dropout02_layerB')(Avgpool_02b)\n",
    "\n",
    "drop02 = keras.layers.concatenate([drop02a,drop02b])\n",
    "\n",
    "# Fully Connected Dense block\n",
    "x = Flatten(name = 'Flatten_layer')(drop02)\n",
    "x = Dense(512, name = 'Dense_layer')(x)\n",
    "x = Dropout(0.5,name = 'Dropout03_layer')(x)\n",
    "logits_layer = Dense(num_classes, name= 'logits_layer')(x)\n",
    "output = Activation('softmax',name = 'Sofftmax_layer')(logits_layer)\n",
    "\n",
    "# Define model inputs and output\n",
    "model = Model(Inp, output)\n",
    "model.summary()\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights('weight.h5')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "#np.save('hist.npy',np.array(hist))\n",
    "##hist = model.fit_generator(datagen.flow(x_train, y_train,\n",
    "##                                 batch_size=batch_size),\n",
    "##                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "##                    epochs=epochs,\n",
    "##                    validation_data=(x_test, y_test),\n",
    "##                    workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weight2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250000 samples, validate on 250000 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train[0::100], y_train[0::100],batch_size//10,\n",
    "                           5,verbose = 2,\n",
    "                           validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
